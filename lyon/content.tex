%!TEX root = ./main.tex
\section{Contribution} % (fold)
\label{sec:contribution}

\subsection{Architecture} % (fold)
\label{sub:architecture}
In order to support the method presented in \ref{sub:method} some technology choices were made. In this section we will present the most important of them and especially detail the structure of our graph-based data model.
\subsubsection{Technologies} % (fold)
\label{ssub:technologies}
\paragraph{Java Language} % (fold)
\label{par:java_language}
Java is a general-purpose computer programming language that is concurrent, class-based, object-oriented, and specifically designed to have as few implementation dependencies as possible. It is also a cross-platform language which means that it would be possible to use it without any recompilation needed. Java is very easy to use, well documented a has the support of a large community (more than 9 million developers reported). Therefore, lot of libraries are available, we will present some of them below. 
% paragraph java_language (end)
\paragraph{Neo4j} % (fold)
\label{par:neo4j}
Graph-based databases are very intuitive to work with and allow the user to model the world as he experience it. The model schema isn't rigid and the user can edit it at anytime, adding new entities or new kind of relationships. Neo4j is an open-source graph database, implemented in Java (so cross-platform), maturing for 15 years and currently running version 2.2. It is the most popular graph database nowadays\footnote{http://db-engines.com/en/ranking/graph+dbms}, has a great scalability, a strong community and has its own query language : Cypher. 
% paragraph neo4j (end)
\paragraph{Semantic Resources Libraries} % (fold)
\label{par:semantic_resources_libraries}
We needed to access the chosen online ontologies (DBpedia's and WordNet's) from our prototype. To achieve this, we used the fact that Java is very popular and lot of libraries are available.\\
We chose Apache JENA ARQ\footnote{https://jena.apache.org/documentation/query/index.html} to query the RDF-base schema of DBpedia. This solution is stable and maintained by a famous structure : Apache. Using it was really simple.\\
Regarding WordNet, we used JAWS\footnote{http://lyle.smu.edu/~tspell/jaws/} which has been developed and is maintain by a member of the Southern Methodist University (Dallas, Texas). Its last version is a bit old but this isn't an issue since WordNet's upgrades have also stopped. This library was also deeply intuitive and easy to use.
% paragraph semantic_resources_libraries (end)
\paragraph{JSoup} % (fold)
\label{par:jsoup}
Our two last experiments are based on Wikipedia's web-pages. Therefore we needed a way to crawl and extract content from them. The JSoup\footnote{http://jsoup.org/} library was a perfect asset to achieve this. It is open-source, implements the WHATWG HTML5 specification, and parses HTML to the same DOM as modern browsers do. It also allows the user to build specific queries to access particular elements in the DOM.
% paragraph jsoup (end)
\paragraph{Stanford NLP} % (fold)
\label{par:stanford_nlp}
Crawling web-pages is a thing, but extracting relevant data from it is another one. The Stanford NLP Research Group\footnote{http://nlp.stanford.edu/} has released several libraries in different programming languages including Java. Those libraries can achieve many things such as sentence segmentation, Part-of-speech (POS) tagging, named entities recognition and so on\dots We used the POS Tagger to extract nouns from Wikipedia paragraphs.
% paragraph stanford_nlp (end)
% subsubsection technologies (end)

\subsubsection{Graph Structure} % (fold)
\label{ssub:graph_structure}
The graph built through the algorithm we developed is an acyclic, directed graph. Its vertexes and edges come from our two chosen semantic resources.
\paragraph{Vertexes} % (fold)
\label{par:vertexes}
Each vertex represents a semantic concept (virtual or real).\\
Virtual ones are concepts created in purpose to perform operations. Here we’re talking about 2 different kinds of nodes :
\begin{description}
	\item[Base concepts] those are created in order to represent the originals tags. Their URIs follow this pattern : “base:TAG” (ex : base:dog)
	\item[Top/Bottom concepts] these two concepts (virtual:top and virtual:bottom) are essential in the compuation of the Wu-Palmer evolved measure (see \ref{par:wu_palmer_evolved}).
\end{description}
Real nodes are semantic nodes linked to semantic entities, classes (DBpedia) or synsets (WordNet) :
\begin{description}
	\item[WordNet's nodes pattern] “Wordnet:TAG” (ex: Wordnet:plant)
	\item[DBpedia's nodes pattern] “DPedia’s concept URI” (ex: http://dbpedia.org/resource/London)
\end{description}
% paragraph vertexes (end)
\paragraph{Edges} % (fold)
\label{par:edges}
There are 3 kind of edges :
\begin{description}
	\item[VIRTUAL] represent virtual links between nodes, not present in any of the semantic resources, created by the algorithm
	\item[EQUIV] represent an equivalence between nodes from 2 different ontologies (ex : http://dbpedia.org/resource/Dog and Wordnet:dog)
	\item[PARENT] represent a semantic link which is of type “is-a” (implemented by the rdfs:subClassOf predicate in DBpedia and the hyperonym/holonym relation in WordNet)
\end{description}
% paragraph edges (end)
\paragraph{Pro-Cons} % (fold)
\label{par:pro_cons}
This graph-based model approach has several benefits : it is more intuitive to imagine the inheritance of a concept, the computation of basic metrics such as shortest path between two concepts or their mLowest Common Subsumer (LCS) is really easy, the schema isn't rigid and has, in fact, evolved during the project \dots\\
However, our choice also has drawbacks : No disambiguation system has been implemented which means that all parents of a node are added to the graph making it always bigger and slower to browse. Given the graph's size and my machine performances, the integration of the Wu-Palmer evolved measure wasn't possible (but implemented and tested on smaller graphs).
% paragraph pro_cons (end)
% subsubsection graph_structure (end)
% subsection architecture (end)

\subsection{Experiments} % (fold)
\label{sub:experiments}
\subsubsection{Implementation Explanation} % (fold)
\label{ssub:implementation_explanation}

% subsubsection implementation_explanation (end)
\subsubsection{Results and Analysis} % (fold)
\label{ssub:results_and_analysis}

% subsubsection results_and_analysis (end)
% subsection experiments (end)

% section contribution (end)

\section{Perspectives} % (fold)
\label{sec:perspectives}
Add new resources
Work with other similarity distances

% section perspectives (end)